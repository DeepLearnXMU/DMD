{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def cal_metrics(labels, answers):\n",
    "    accuracy = accuracy_score(labels, answers)\n",
    "    precision = precision_score(labels, answers)\n",
    "    recall = recall_score(labels, answers)\n",
    "    f1 = f1_score(labels, answers)\n",
    "\n",
    "    return {\"acc\": accuracy, \"prec\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "\n",
    "def load_data(path, train_dataset=None, train=False):\n",
    "    def remove_non_letters(s):\n",
    "        return re.sub(r\"^[^a-zA-Z]+|[^a-zA-Z]+$\", \"\", s)\n",
    "\n",
    "    with open(\"../data/dictionary.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        dictionary = json.load(f)\n",
    "\n",
    "    with open(\"../data/contexts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        contexts = json.load(f)\n",
    "\n",
    "    if train_dataset is not None:\n",
    "        with open(os.path.join(path, \"distances.json\"), \"r\") as f:\n",
    "            distances = json.load(f)\n",
    "\n",
    "        with open(os.path.join(path, \"vals.json\"), \"r\") as f:\n",
    "            vals = json.load(f)\n",
    "\n",
    "    if train:\n",
    "        data_path = os.path.join(path, \"train.tsv\")\n",
    "    else:\n",
    "        data_path = os.path.join(path, \"test.tsv\")\n",
    "\n",
    "    labels = []\n",
    "    dataset = []\n",
    "\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for index, line in enumerate(lines):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        cells = line.strip().split(\"\\t\")\n",
    "\n",
    "        label = int(cells[1])\n",
    "        sent = cells[2]\n",
    "        POS = cells[3]\n",
    "        v_index = int(cells[-1])\n",
    "        word = remove_non_letters(sent.split()[v_index])\n",
    "\n",
    "        splits = sent.split()\n",
    "        splits.insert(v_index, \"<tar>\")\n",
    "        splits.insert(v_index + 2, \"</tar>\")\n",
    "\n",
    "        sample = {\"sentence\": sent, \"word\": word, \"label\": label, \"pos\": POS, \"v_index\": v_index, \"s_sentence\": \" \".join(splits)}\n",
    "        if train_dataset is not None:\n",
    "            shots = random.sample(train_dataset, 10)\n",
    "\n",
    "            sample[\"shots\"] = shots\n",
    "        if train_dataset is not None:\n",
    "            samples_distances = distances[index - 1]\n",
    "            samples_ids = vals[index - 1]\n",
    "            sample[\"samples_distances\"] = samples_distances\n",
    "            sample[\"samples_knn\"] = [train_dataset[_id] for _id in samples_ids]\n",
    "        word = word.lower()\n",
    "        base_words = [word]\n",
    "        for pos in [\"v\", \"a\", \"r\", \"s\", \"n\"]:\n",
    "            base_word = lemmatizer.lemmatize(word, pos)\n",
    "            if base_word in base_words:\n",
    "                continue\n",
    "            base_words.append(base_word)\n",
    "\n",
    "        for word in base_words:\n",
    "            if word in dictionary:\n",
    "                dict_info = dictionary[word.lower()]\n",
    "                sample[\"dict_word\"] = word\n",
    "                sample[\"dict\"] = dict_info\n",
    "                break\n",
    "            else:\n",
    "                sample[\"dict\"] = {}\n",
    "\n",
    "        for word in base_words:\n",
    "            if word in contexts:\n",
    "                sample[\"pos_sent\"] = contexts[word][\"pos\"][0]\n",
    "                sample[\"neg_sent\"] = contexts[word][\"neg\"][0]\n",
    "                sample[\"exam_word\"] = word\n",
    "                break\n",
    "\n",
    "        dataset.append(sample)\n",
    "        labels.append(int(cells[1]))\n",
    "\n",
    "    return dataset, labels\n",
    "train_dataset, _ = load_data(\"../data/VUA18\", train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "llm_type = \"gpt-4o-2024-08-06\"\n",
    "api_key = \"\"\n",
    "api_base = \"\"\n",
    "client = OpenAI(api_key=api_key, base_url=api_base)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "global_vars = {\"EXAMNUM\": 2}\n",
    "\n",
    "\n",
    "def get_response(llm_type, prompt, temp=1.0):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=llm_type,\n",
    "        stream=False,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temp,\n",
    "        timeout=600,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def load_prompts(dataset, func):\n",
    "    res = []\n",
    "    for data in dataset:\n",
    "        res.append(func(data))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def knn_cot_prompt_func(data):\n",
    "    example_template = \"\"\"Example {no}:\n",
    "Sentence: {sentence}\n",
    "Word: {word}\n",
    "Answer: {answer}\\n\\n\"\"\"\n",
    "\n",
    "    system = \"\"\"Does the given word in the given sentence express metaphorical meaning? Please give an answer 'yes' or 'no' like examples below and give your explanation.\\n\\n\"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"Sentence: {sentence}\n",
    "Word: {word}\n",
    "Answer: \"\"\"\n",
    "    examples_prompts = \"\"\n",
    "    for index, example in enumerate(data[\"samples_knn\"][: global_vars[\"EXAMNUM\"]]):\n",
    "        examples_prompts += example_template.format(\n",
    "            no=index + 1, sentence=example[\"sentence\"], word=example[\"word\"], answer=\"yes\" if example[\"label\"] == 1 else \"no\"\n",
    "        )\n",
    "\n",
    "    return system + examples_prompts + \"\\n\" + prompt_template.format(sentence=data[\"sentence\"], word=data[\"word\"])\n",
    "\n",
    "\n",
    "for times in [1, 2, 3]:\n",
    "    for data_name in [\n",
    "        \"MOH-X\",\n",
    "        \"TroFi\",\n",
    "    ]:\n",
    "        KNN=8\n",
    "        setting = f\"implicit-{KNN}-{times}\"\n",
    "        global_vars[\"EXAMNUM\"] = KNN\n",
    "\n",
    "        data_dir = f\"../data/EVAL-samples/{data_name}\"\n",
    "\n",
    "        output_dir = f\"./results/{setting}/{data_name}/{llm_type}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"===================={output_dir}=====================\")\n",
    "        dataset, labels = load_data(data_dir, train_dataset=train_dataset)\n",
    "\n",
    "\n",
    "        prompts = load_prompts(dataset, knn_cot_prompt_func)\n",
    "\n",
    "        with open(os.path.join(output_dir, \"prompts.json\"), \"w\") as f:\n",
    "            json.dump(prompts, f)\n",
    "        while True:\n",
    "            try:\n",
    "                with open(os.path.join(output_dir, \"responses.json\"), \"r\") as f:\n",
    "                    responses = json.load(f)\n",
    "            except:\n",
    "                responses = []\n",
    "            if len(dataset) == len(responses):\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                for index, prompt in tqdm(enumerate(prompts[len(responses) :]), total=len(prompts) - len(responses)):\n",
    "                    response = get_response(llm_type, prompt, temp=0.0)\n",
    "                    responses.append(response)\n",
    "                    if index % 50 == 0:\n",
    "                        with open(os.path.join(output_dir, \"responses.json\"), \"w\") as f:\n",
    "                            json.dump(responses, f)\n",
    "\n",
    "            except Exception as e:\n",
    "                with open(os.path.join(output_dir, \"responses.json\"), \"w\") as f:\n",
    "                    json.dump(responses, f)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "            with open(os.path.join(output_dir, \"responses.json\"), \"w\") as f:\n",
    "                json.dump(responses, f)\n",
    "\n",
    "        def extract_answer(response):\n",
    "            if \"yes\" in response.lower():\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        preds = [extract_answer(response) for response in responses]\n",
    "        with open(os.path.join(output_dir, \"preds.json\"), \"w\") as f:\n",
    "            json.dump(preds, f)\n",
    "\n",
    "        metrics = cal_metrics(labels, preds)\n",
    "        with open(os.path.join(output_dir, \"metrics.json\"), \"w\") as f:\n",
    "            json.dump(metrics, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
